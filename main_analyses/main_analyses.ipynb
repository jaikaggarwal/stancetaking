{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jai\\Desktop\\BGP-WordEmbedding\\BGP_venv\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Jai\\Desktop\\BGP-WordEmbedding\\BGP_venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "c:\\Users\\Jai\\Desktop\\BGP-WordEmbedding\\BGP_venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from data_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_dim_to_keep(total_var_explained, label):\n",
    "    if label.endswith(\"8_dim\"):\n",
    "        return 8\n",
    "    elif label.endswith(\"3_dim\"):\n",
    "        return 3\n",
    "    else:\n",
    "        return np.argmax(total_var_explained>0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we even need df? Can we just save need probabilities?\n",
    "df = Serialization.load_obj(f\"stance_pipeline_full_data_{NUM_QUANTILES}_quantiles_full_data\")\n",
    "x = df.groupby(\"bin\").mean()[FEATURE_COLUMNS]\n",
    "df = get_sub_marker_pairs(df)\n",
    "# Write unit test for below\n",
    "bins, comms, markers, com_markers = get_bin_com_markers(df, bins, comms)\n",
    "pav_matrix = Serialization.load_obj(\"pavalanathan_cooc_data_full_data\")\n",
    "cooc_matrix = Serialization.load_obj(\"our_cooc_data_full_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = [cooc_matrix, cooc_matrix, cooc_matrix, pav_matrix, pav_matrix, pav_matrix, pav_matrix]\n",
    "labels = [\"our_ppmi_3_dim\", \"our_raw_90_var\", \"our_ppmi_8_dim\", \"pav_raw_8_dim\", \"pav_ppmi_8_dim\", \"pav_raw_90_var\", \"pav_ppmi_90_var\"]\n",
    "delegates = [lambda x: create_derived_representation(x, include_ppmi=True), lambda x: create_derived_representation(x, include_ppmi=False), lambda x: create_derived_representation(x, include_ppmi=True), lambda x: create_derived_representation(x, include_ppmi=False), lambda x: create_derived_representation(x, include_ppmi=True), lambda x: create_derived_representation(x, include_ppmi=False), lambda x: create_derived_representation(x, include_ppmi=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "for matrix, label, delegate in zip(matrices, labels, delegates):\n",
    "    curr_output = delegate(matrix)\n",
    "    all_data[label] = curr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    eigenvalues, var_explained, total_var_explained = scree_plot(all_data[label]['singular_values'], to_show=False)\n",
    "    all_data[label]['eigenvalues'] = eigenvalues\n",
    "    all_data[label]['var_explained'] = var_explained\n",
    "    all_data[label]['total_var_explained'] = total_var_explained\n",
    "    all_data[label]['num_dim_to_keep'] = num_dim_to_keep(total_var_explained, label)\n",
    "    all_data[label]['new_sem_rep'] = all_data[label]['sem_rep'][:, :all_data[label]['num_dim_to_keep']]\n",
    "    all_data[label]['new_marker_rep'] = all_data[label]['marker_rep'].T[:, :all_data[label]['num_dim_to_keep']].reshape(-1, all_data[label]['num_dim_to_keep'])\n",
    "    all_data[label]['new_sem_loadings'] = all_data[label]['sem_loadings'][:, :all_data[label]['num_dim_to_keep']]\n",
    "    all_data[label]['new_marker_loadings'] = all_data[label]['marker_loadings'].T[:, :all_data[label]['num_dim_to_keep']].reshape(-1, all_data[label]['num_dim_to_keep'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-08d1e193798c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_dim_to_keep'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'total_var_explained'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_dim_to_keep'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(label)\n",
    "    print(all_data[label]['num_dim_to_keep'])\n",
    "    print(all_data[label]['total_var_explained'][all_data[label]['num_dim_to_keep']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_to_stance_usage = {\"our_raw_90_var\": {}, \"our_ppmi_8_dim\": {}}\n",
    "comms = sorted(comms)\n",
    "for i in range(len(comms)):\n",
    "    sub = all_data['our_raw_90_var']['new_marker_loadings'][i*len(markers):(i+1)*len(markers), :]\n",
    "    com_to_stance_usage['our_raw_90_var'][comms[i]] = sub\n",
    "    sub = all_data['our_ppmi_8_dim']['new_marker_loadings'][i*len(markers):(i+1)*len(markers), :]\n",
    "    com_to_stance_usage['our_ppmi_8_dim'][comms[i]] = sub\n",
    "    # sub.columns = [col[col.index(\"_\") + 1:] for col in sub.columns]\n",
    "    \n",
    "\n",
    "pav_comms = pav_matrix.index.tolist()\n",
    "for label in tqdm(labels):\n",
    "    # pav_full_vals = []\n",
    "    # pav_partial_vals = []\n",
    "    # our_full_vals = []\n",
    "    # our_partial_vals = []\n",
    "    full_vals = []\n",
    "    partial_vals = []\n",
    "    for i, row in crossposting_df.iterrows():\n",
    "        com_1, com_2 = row['com_1'], row['com_2']\n",
    "        if label.startswith(\"pav\"):\n",
    "            # Pav data\n",
    "            ci1, ci2 = pav_comms.index(com_1), pav_comms.index(com_2)\n",
    "            ci1_rep = all_data[label]['new_sem_loadings'][ci1].reshape(1, -1)\n",
    "            ci2_rep = all_data[label]['new_sem_loadings'][ci2].reshape(1, -1)\n",
    "            pav_full = cosine_similarity(ci1_rep, ci2_rep)[0][0]\n",
    "            full_vals.append(pav_full)\n",
    "\n",
    "            pav_partial = np.abs(ci1_rep - ci2_rep)[0]\n",
    "            partial_vals.append(pav_partial)\n",
    "        else:\n",
    "            # Our Data\n",
    "            full_vals.append(np.mean(cosine_similarity(com_to_stance_usage[label][com_1], com_to_stance_usage[label][com_2]).diagonal()))\n",
    "            partial_vals.append(np.abs(com_to_stance_usage[label][com_1] - com_to_stance_usage[label][com_2]).sum(axis=0))\n",
    "    all_data[label]['full_crosspost'] = full_vals\n",
    "    all_data[label]['partial_crosspost'] = partial_vals\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CV = 5\n",
    "L1_RATIO=0.5\n",
    "\n",
    "    \n",
    "df_data = []\n",
    "for label in labels:\n",
    "    lr = LogisticRegression(random_state=42, penalty='l2', solver=\"lbfgs\")#, l1_ratio=L1_RATIO)\n",
    "    full_scores = cross_val_score(lr, np.array(all_data[label]['full_crosspost']).reshape(-1, 1), crossposting_df['label'].tolist(), cv=NUM_CV)\n",
    "    print(label)\n",
    "    print(\"Full:%0.2f accuracy with a standard deviation of %0.2f\" % (full_scores.mean(), full_scores.std()))\n",
    "\n",
    "    lr = LogisticRegression(random_state=42, penalty='l2', solver=\"lbfgs\", max_iter=100000)#, l1_ratio=L1_RATIO)\n",
    "    partial_scores = cross_val_score(lr, np.array(all_data[label]['partial_crosspost']).reshape(-1, all_data[label]['num_dim_to_keep']), crossposting_df['label'].tolist(), cv=NUM_CV)\n",
    "    print(\"Partial: %0.2f accuracy with a standard deviation of %0.2f\" % (partial_scores.mean(), partial_scores.std()))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    df_data.append([label, full_scores.mean(), partial_scores.mean()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 ('BGP_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80932d381690da30b9358f344178503845394e322c86997319184daf72c99e75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
