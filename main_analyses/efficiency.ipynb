{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_utils import *\n",
    "from scipy.stats.contingency import margins\n",
    "np.seterr(divide='ignore', invalid=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do we even need df? Can we just save need probabilities?\n",
    "# df = Serialization.load_obj(f\"stance_pipeline_full_data_{NUM_QUANTILES}_quantiles_full_data\")\n",
    "# bin_means = df.groupby(\"bin\").mean()[FEATURE_COLUMNS]\n",
    "# df = get_sub_marker_pairs(df)\n",
    "# # Write unit test for below\n",
    "# bins, comms, markers, com_markers = get_bin_com_markers(df)\n",
    "pav_matrix = Serialization.load_obj(\"pavalanathan_cooc_data_full_data\")\n",
    "cooc_matrix = Serialization.load_obj(\"our_cooc_data_full_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBObj:\n",
    "\n",
    "    def __init__(self, com_name, joint):\n",
    "        \"\"\"\n",
    "        Holds all information related to the efficiency calculation for a particular community.\n",
    "        Args:\n",
    "            com_name (str): the community that efficiency is being calculated for\n",
    "        \"\"\"\n",
    "        self.com_name = com_name\n",
    "        self.joint = (joint/joint.sum()).T\n",
    "        self.p_m, self.p_w = margins(self.joint)\n",
    "        self.encoder = self.joint/self.p_m\n",
    "        self.decoder = self.compute_listener_distribution()\n",
    "        self.complexity = self.compute_complexity()\n",
    "        self.informativeness = self.compute_informativeness()\n",
    "\n",
    "    def compute_info_gain(self, joint, marginal_1, marginal_2):\n",
    "        joint_info = np.log2(joint/(np.multiply(marginal_1, marginal_2)))\n",
    "        expanded = np.nan_to_num(np.multiply(joint, joint_info), 0)\n",
    "        total = expanded.sum()\n",
    "        return total\n",
    "\n",
    "    def compute_listener_distribution(self):\n",
    "        return self.joint/self.p_w\n",
    "\n",
    "    def compute_complexity(self):\n",
    "        return self.compute_info_gain(self.joint, self.p_w, self.p_m)\n",
    "    \n",
    "    def compute_informativeness(self):\n",
    "        listener_surprisal = np.log2(1/self.decoder)\n",
    "        expanded = np.nan_to_num(np.multiply(self.joint, listener_surprisal), 0)\n",
    "        total = expanded.sum()\n",
    "        return total\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n",
      "1.375\n"
     ]
    }
   ],
   "source": [
    "min_complexity_encoder = np.array([[1, 1, 1, 1]])\n",
    "max_complexity_encoder = np.diag(np.ones(4))\n",
    "# rows are words\n",
    "# columns are meanings\n",
    "# This gets flipped in IBObj\n",
    "mid_complexity_encoder = np.array([\n",
    "    [1/8, 1/16, 1/32, 1/32],\n",
    "    [1/16, 1/8, 1/32, 1/32],\n",
    "    [1/16, 1/16, 1/16, 1/16],\n",
    "    [1/4, 0, 0, 0]\n",
    "])\n",
    "ex_min = IBObj(\"min_comp\", min_complexity_encoder)\n",
    "ex_max = IBObj(\"max_comp\", max_complexity_encoder)\n",
    "ex_mid = IBObj(\"mid_comp\", mid_complexity_encoder)\n",
    "\n",
    "print(ex_mid.complexity)\n",
    "print(ex_mid.informativeness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_hat(qW_M, pM, pU_M):\n",
    "    \"\"\"\n",
    "    :param qW_M: encoder (naming system)\n",
    "    :return: optimal decoder (Bayesian listener) that corresponds to the encoder\n",
    "    \"\"\"\n",
    "    # Each row is a meaning, each column is a word\n",
    "    pMW = qW_M * pM\n",
    "    pM_W = pMW.T / pMW.sum(axis=0)[:, None]\n",
    "    return pM_W.dot(pU_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:00<00:00, 101.92it/s]\n"
     ]
    }
   ],
   "source": [
    "all_dfs = []\n",
    "com_to_markers = {}\n",
    "for i in tqdm(range(92)):\n",
    "    curr = cooc_matrix.T.iloc[i*1112:(i+1)*1112].T\n",
    "    all_dfs.append(curr)\n",
    "\n",
    "all_ibs = []\n",
    "for curr in all_dfs:\n",
    "    com_name = curr.columns[0].split(\"_\")[0]\n",
    "    if com_name == \"photoshopbattles\":\n",
    "        continue\n",
    "    encoder = curr.T.to_numpy()\n",
    "    curr_IB = IBObj(com_name, encoder)\n",
    "    all_ibs.append(curr_IB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "PRECISION = 1e-16\n",
    "\n",
    "def marginal(pXY, axis=1):\n",
    "    \"\"\":return pY (axis = 0) or pX (default, axis = 1)\"\"\"\n",
    "    return pXY.sum(axis)\n",
    "\n",
    "def conditional(pXY):\n",
    "    \"\"\":return  pY_X \"\"\"\n",
    "    pX = pXY.sum(axis=1, keepdims=True)\n",
    "    return np.where(pX > PRECISION, pXY / pX, 1 / pXY.shape[1])\n",
    "\n",
    "def joint(pY_X, pX):\n",
    "    \"\"\":return  pXY \"\"\"\n",
    "    return pY_X * pX[:, None]\n",
    "\n",
    "def marginalize(pY_X, pX):\n",
    "    \"\"\":return  pY \"\"\"\n",
    "    return pY_X.T @ pX\n",
    "\n",
    "def bayes(pY_X, pX):\n",
    "    \"\"\":return pX_Y \"\"\"\n",
    "    pXY = joint(pY_X, pX)\n",
    "    pY = marginalize(pY_X, pX)\n",
    "    return np.where(pY > PRECISION, pXY.T / pY, 1 / pXY.shape[0])\n",
    "\n",
    "def softmax(dxy, beta=1, axis=None):\n",
    "    \"\"\":return\n",
    "        axis = None: pXY propto exp(-beta * dxy)\n",
    "        axis = 1: pY_X propto exp(-beta * dxy)\n",
    "        axis = 0: pX_Y propto exp(-beta * dxy)\n",
    "    \"\"\"\n",
    "    log_z = logsumexp(-beta * dxy, axis, keepdims=True)\n",
    "    return np.exp(-beta * dxy - log_z)\n",
    "\n",
    "# INFORMATIONAL MEASURES\n",
    "\n",
    "def xlogx(v):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        return np.where(v > PRECISION, v * np.log2(v), 0)\n",
    "\n",
    "def H(p, axis=None):\n",
    "    \"\"\" Entropy \"\"\"\n",
    "    return -xlogx(p).sum(axis=axis)\n",
    "\n",
    "def MI(pXY):\n",
    "    \"\"\" mutual information, I(X;Y) \"\"\"\n",
    "    return H(pXY.sum(axis=0)) + H(pXY.sum(axis=1)) - H(pXY)\n",
    "\n",
    "def DKL(p, q, axis=None):\n",
    "    \"\"\" KL divergences, D[p||q] \"\"\"\n",
    "    return (xlogx(p) - np.where(p > PRECISION, p * np.log2(q + PRECISION), 0)).sum(axis=axis)\n",
    "\n",
    "def gNID(pW_X, pV_X, pX):\n",
    "    if len(pX.shape) == 1:\n",
    "        pX = pX[:, None]\n",
    "    elif pX.shape[0] == 1 and pX.shape[1] > 1:\n",
    "        pX = pX.T\n",
    "    pXW = pW_X * pX\n",
    "    pWV = pXW.T.dot(pV_X)\n",
    "    pWW = pXW.T.dot(pW_X)\n",
    "    pVV = (pV_X * pX).T.dot(pV_X)\n",
    "    score = 1 - MI(pWV) / (np.max([MI(pWW), MI(pVV)]))\n",
    "    return score\n",
    "\n",
    "def complexity_joint(pWM):\n",
    "    \"\"\"\n",
    "    :param pW_M: encoder (naming system)\n",
    "    :return: I(M;W)\n",
    "    \"\"\"\n",
    "    return MI(pWM)\n",
    "\n",
    "def complexity_split(pW_M, pM):\n",
    "    \"\"\"\n",
    "    :param pW_M: encoder (naming system)\n",
    "    :return: I(M;W)\n",
    "    \"\"\"\n",
    "    return MI(pW_M * pM)\n",
    "\n",
    "\n",
    "def accuracy(pW_M, pM, pU_M):\n",
    "    \"\"\"\n",
    "    :param pW_M: encoder (naming system)\n",
    "    :return: I(W;U)\n",
    "    \"\"\"\n",
    "    pMW = pW_M * pM\n",
    "    pWU = pMW.T @ pU_M\n",
    "    return MI(pWU)\n",
    "    \n",
    "\n",
    "class IBNamingModel(object):\n",
    "\n",
    "    def __init__(self, pM, pU_M, betas, IB_curve, qW_M):\n",
    "        self.pM = pM if len(pM.shape) == 2 else pM[:, None]\n",
    "        self.pU_M = pU_M\n",
    "        self.I_MU = MI(pU_M * self.pM)\n",
    "        self.betas = betas\n",
    "        self.IB_curve = IB_curve\n",
    "        self.qW_M = qW_M\n",
    "        self.qW_M_orig = None\n",
    "        self.F = IB_curve[0] - betas * IB_curve[1]\n",
    "\n",
    "    def m_hat(self, qW_M):\n",
    "        \"\"\"\n",
    "        :param qW_M: encoder (naming system)\n",
    "        :return: optimal decoder (Bayesian listener) that corresponds to the encoder\n",
    "        \"\"\"\n",
    "        pMW = qW_M * self.pM\n",
    "        pM_W = pMW.T / pMW.sum(axis=0)[:, None]\n",
    "        return pM_W.dot(self.pU_M)\n",
    "\n",
    "    def complexity(self, pW_M):\n",
    "        \"\"\"\n",
    "        :param pW_M: encoder (naming system)\n",
    "        :return: I(M;W)\n",
    "        \"\"\"\n",
    "        return MI(pW_M * self.pM)\n",
    "\n",
    "    def accuracy(self, pW_M):\n",
    "        \"\"\"\n",
    "        :param pW_M: encoder (naming system)\n",
    "        :return: I(W;U)\n",
    "        \"\"\"\n",
    "        pMW = pW_M * self.pM\n",
    "        pWU = pMW.T @ self.pU_M\n",
    "        return MI(pWU)\n",
    "\n",
    "    def d_IB(self, pW_M):\n",
    "        \"\"\"\n",
    "        :param pW_M: encoder (naming system)\n",
    "        :return: E[D[m||m_hat]] = I(M;U) - I(W;U)\n",
    "        \"\"\"\n",
    "        return self.I_MU - self.accuracy(pW_M)\n",
    "\n",
    "    def fit(self, pW_M):\n",
    "        \"\"\"\n",
    "        fits the naming system by\n",
    "        :param pW_M: encoder (naming system)\n",
    "        :return:\n",
    "            epsilon - deviation from optimality of pW_M\n",
    "            gnid - gNID between qW_M and qW_M_fit\n",
    "            bl - beta_l, the value of beta that was fitted to pW_M\n",
    "            qW_M_fit - the optimal IB system at bl\n",
    "        \"\"\"\n",
    "        Fl = self.complexity(pW_M) - self.betas * self.accuracy(pW_M)\n",
    "        dFl = Fl - self.F\n",
    "        bl_ind = dFl.argmin()\n",
    "        bl = self.betas[bl_ind]\n",
    "        epsilon = dFl.min() / bl\n",
    "        qW_M_fit = self.qW_M[bl_ind]\n",
    "        gnid = gNID(pW_M, qW_M_fit, self.pM)\n",
    "        return epsilon, gnid, bl, qW_M_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit tests\n",
    "# Assert that we calculate the decoder the same as them\n",
    "np.testing.assert_equal(ex_mid.decoder.T, m_hat(ex_mid.encoder, ex_mid.p_m, np.diag(np.ones(4))))\n",
    "\n",
    "# Assert that our mutual information calculation is correct\n",
    "np.testing.assert_equal(ex_mid.compute_info_gain(ex_mid.joint, ex_mid.p_w, ex_mid.p_m), MI(ex_mid.joint))\n",
    "\n",
    "# Assert that we are using DKL properly\n",
    "test_a = np.array([9/25, 12/25, 4/25])\n",
    "test_b = np.repeat(np.array([1/3, 1/3, 1/3])[:, np.newaxis], 3, axis=1)\n",
    "np.testing.assert_almost_equal(DKL(test_a, test_b, axis=1), [0.1230613, 0.1230613, 0.1230613])\n",
    "\n",
    "# Assert that the complexity functions return values as we would expect\n",
    "np.testing.assert_equal(complexity_split(ex_mid.encoder, ex_mid.p_m), complexity_joint(ex_mid.joint))\n",
    "np.testing.assert_equal(ex_mid.complexity, complexity_joint(ex_mid.joint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/ais/hal9000/datasets/reddit/stance_pipeline/classifiers/\"\n",
    "filename = \"zaslavsky_colour_model.pkl\"\n",
    "import pickle\n",
    "data = pickle.load(open(model_dir + filename, 'rb'))\n",
    "beta_schedule = data['betas'][::-1]\n",
    "pm = data['pM']\n",
    "pu_m = data['pU_M']\n",
    "ib_curve = data['IB_curve']\n",
    "qw_m = data['qW_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asserts that meanings are the rows, and columns are each stimulus\n",
    "np.testing.assert_almost_equal(pu_m.sum(axis=1), np.ones(len(pm)))\n",
    "# Assert multiplying in this way creates a proper joint dist\n",
    "np.testing.assert_almost_equal((pu_m * pm).sum(), 1)\n",
    "# Assert that the marginals of the joint are indeed pm\n",
    "np.testing.assert_almost_equal((pu_m * pm).sum(axis=1).reshape(-1, 1), pm.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint = np.diag(np.ones(330)) * pm\n",
    "# First equation calculated: pw solved\n",
    "# new_pm, new_pw = margins(joint)\n",
    "# new_pw_m = np.zeros((330, 330))\n",
    "# for i in range(len(pm)):\n",
    "#     div = DKL(pu_m[i, :], pu_w[i, :])\n",
    "#     new_pw_m[i, :] = new_pw * np.exp(-1*div)\n",
    "#     new_pw_m = new_pw_m/new_pw_m.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0072590738423028"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_schedule[-60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_encoder = np.diag(np.ones(330))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.347510789285019"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(qw_m[1200], pm, pu_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from psuedo algorithm here: https://www.nogsky.com/publication/2019-evo-ib/2019-evo-IB.pdf\n",
    "def reverse_annealing(pm, pu_m, init_qwm, betas):\n",
    "    # encoder is conditional probability of w|m\n",
    "    # pm is marginal probability\n",
    "    #assert joint.shape == (1024, 1024) # we want words to be on the rows, meanings on the columns\n",
    "    curr_encoder = init_qwm#np.diag(np.ones(len(pm)))\n",
    "    encoder_list = [curr_encoder]\n",
    "    for i in tqdm(range(len(betas))):\n",
    "        # if i == 1:\n",
    "        #     break\n",
    "        # Initial joint is just the initial encoder multiplied by p(m)\n",
    "        new_encoder = deterministic_annealing(pm, pu_m, curr_encoder, betas[i])\n",
    "        encoder_list.append(new_encoder)\n",
    "        curr_encoder = new_encoder\n",
    "    return encoder_list\n",
    "\n",
    "def deterministic_annealing(pm, pu_m, qw_m, beta):\n",
    "    curr_encoder = qw_m\n",
    "    prev_f = 100\n",
    "    new_f = complexity_split(curr_encoder, pm) - beta * accuracy(curr_encoder, pm, pu_m)\n",
    "    loops = 0\n",
    "    while np.abs(prev_f - new_f) >= 1e-6:\n",
    "        loops += 1\n",
    "        if loops >= 10:\n",
    "            break\n",
    "        \n",
    "        joint = curr_encoder * pm\n",
    "        np.testing.assert_almost_equal(joint.sum(), 1)\n",
    "        # First equation calculated: pw solved\n",
    "        new_pm, new_pw = margins(joint)\n",
    "        print(new_pw.shape)\n",
    "        new_pu_w =  np.nan_to_num(m_hat(curr_encoder, pm, pu_m), 0)\n",
    "        # Instead of KL Divergence, for our case use 1/decoder as we have been\n",
    "        new_pw_m = np.zeros((len(pm), len(new_pw[0])))\n",
    "        # print(new_pw_m.shape)\n",
    "        # assert new_pw_m.shape == (330, 330)\n",
    "        for i in range(len(pm)):\n",
    "            div = DKL(pu_m[i, :], new_pu_w, axis=1)\n",
    "            new_pw_m[i, :] = new_pw * np.exp(-beta*div)\n",
    "        # new_pw_m = new_pw_m/new_pw_m.sum(axis=1).reshape(-1, 1)\n",
    "        # new_pw_m[new_pw_m<1e-45] = 0\n",
    "        # new_pw_m = new_pw_m/new_pw_m.sum(axis=1).reshape(-1, 1)\n",
    "        if loops == 1:\n",
    "            return new_pw_m, new_pw, pu_m, new_pu_w, beta, curr_encoder\n",
    "        # I_MU = MI(pm * pu_m)\n",
    "        # divergence = I_MU - accuracy(curr_encoder, pm, pu_m)\n",
    "        # print(\"Divergence:\", divergence)\n",
    "        # new_encoder = new_pw * np.exp(-beta * divergence)\n",
    "        new_encoder = new_pw_m\n",
    "        # print(new_encoder)\n",
    "\n",
    "        Fl = complexity_split(new_encoder, pm) - beta * accuracy(new_encoder, pm, pu_m)\n",
    "        # new variable setting\n",
    "        prev_f = new_f\n",
    "        new_f = Fl\n",
    "        curr_encoder = new_encoder\n",
    "        # print(prev_f)\n",
    "        # print(new_f)\n",
    "        # print(prev_f - new_f)\n",
    "    # print(\"Loops:\", loops)\n",
    "    # print(prev_f - new_f)\n",
    "    return curr_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pw_m, new_pw, pu_m, new_pu_w, beta, curr_encoder = o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = vlog(self.qt)-self.beta*kl(self.ds.py_x[:,x],self.qy_t) # [=] T x 1 # scales like X*Y*T\n",
    "if self.alpha==0: self.qt_x[np.argmax(l),x] = 1\n",
    "else: self.qt_x[:,x] = vexp(l/self.alpha)/np.sum(vexp(l/self.alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def da(pm, pu_m, qw_m, beta):\n",
    "    CONV_THRESHOLD = 1e-16\n",
    "    curr_encoder = qw_m\n",
    "    prev_f = 100\n",
    "    new_f = complexity_split(curr_encoder, pm) - beta*accuracy(curr_encoder, pm, pu_m)\n",
    "\n",
    "    curr_joint = curr_encoder * pm\n",
    "    np.testing.assert_almost_equal(curr_joint.sum(), 1)\n",
    "    curr_pm, curr_pw = margins(curr_joint)\n",
    "    np.testing.assert_almost_equal(curr_pm, pm)\n",
    "    curr_mhat = m_hat(curr_encoder, pm, pu_m)\n",
    "\n",
    "    while np.abs(prev_f - new_f) >= CONV_THRESHOLD:\n",
    "        new_encoder_vals = []\n",
    "        for i in range(len(pm)):\n",
    "            div = DKL(pu_m[i], curr_mhat, axis=1)\n",
    "            new_encoder_vals.append(div)\n",
    "        stacked = np.stack(new_encoder_vals)\n",
    "        sa = softmax(stacked, beta=beta, axis=1)\n",
    "        pwsa = curr_pw*sa\n",
    "        new_encoder = (pwsa/pwsa.sum(axis=1).reshape(-1, 1))\n",
    "        assert new_encoder.shape == curr_encoder.shape\n",
    "\n",
    "        \n",
    "        new_pm, new_pw = margins(new_encoder * pm)\n",
    "\n",
    "        new_mhat = m_hat(new_encoder, pm, pu_m)\n",
    "\n",
    "        curr_encoder = new_encoder\n",
    "        curr_pw = new_pw\n",
    "        curr_mhat = new_mhat\n",
    "\n",
    "        prev_f = new_f\n",
    "        new_f = complexity_split(curr_encoder, pm) - beta*accuracy(curr_encoder, pm, pu_m)\n",
    "    return curr_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 249)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29950/3081288226.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mold_da\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeterministic_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpu_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqw_m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_schedule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_da\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpu_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqw_m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_schedule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_29950/2147107854.py\u001b[0m in \u001b[0;36mda\u001b[0;34m(pm, pu_m, qw_m, beta)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnew_encoder_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDKL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpu_m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_mhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mnew_encoder_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mstacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_encoder_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_29950/768755777.py\u001b[0m in \u001b[0;36mDKL\u001b[0;34m(p, q, axis)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mDKL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;34m\"\"\" KL divergences, D[p||q] \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxlogx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mPRECISION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mPRECISION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgNID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpW_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpV_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 300\n",
    "old_da = deterministic_annealing(pm, pu_m, qw_m[-i], beta_schedule[-i])\n",
    "new_da = da(pm, pu_m, qw_m[-i], beta_schedule[-i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Old True Complexity: \", ib_curve[0][-i])\n",
    "print(\"Old Encoder Complexity: \", complexity_split(qw_m[-i], pm))\n",
    "print(\"New True Complexity: \", ib_curve[0][-i-1])\n",
    "print(\"New Encoder Complexity: \", complexity_split(qw_m[-i-1], pm))\n",
    "print(\"Our Old Complexity: \", complexity_split(old_da, pm))\n",
    "print(\"Our New Complexity: \", complexity_split(new_da, pm))\n",
    "\n",
    "\n",
    "print(\"Old True Accuracy: \", ib_curve[1][-i])\n",
    "print(\"Old Encoder Accuracy: \", accuracy(qw_m[-i], pm, pu_m))\n",
    "print(\"New True Accuracy: \", ib_curve[1][-i-1])\n",
    "print(\"New Encoder Accuracy: \", accuracy(qw_m[-i-1], pm, pu_m))\n",
    "print(\"Our Old Accuracy: \", accuracy(old_da, pm, pu_m))\n",
    "print(\"Our New Accuracy: \", accuracy(new_da, pm, pu_m))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01462499, 0.00141208, 0.01516417])"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = da(pm, pu_m, qw_m[1400], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 249)\n"
     ]
    }
   ],
   "source": [
    "i = 300\n",
    "o = deterministic_annealing(pm, pu_m, qw_m[-i], beta_schedule[-i])\n",
    "# print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old True Complexity:  6.383602136055115\n",
      "Old Encoder Complexity:  6.383602107256618\n",
      "New True Complexity:  6.375372674636497\n",
      "New Encoder Complexity:  6.375372675031595\n",
      "Our Complexity:  6.486067751506913\n",
      "Old True Accuracy:  4.348025928956325\n",
      "Old Encoder Accuracy:  4.348025927177895\n",
      "New True Accuracy:  4.347510789261797\n",
      "New Encoder Accuracy:  4.347510789285019\n",
      "Our Accuracy:  4.353454695917527\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8104336235830694"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_encoders = reverse_annealing(pm, pu_m, qw_m[500], beta_schedule[100:500][::-1])\n",
    "new_comp = []\n",
    "new_acc = []\n",
    "for e in tqdm(new_encoders):\n",
    "    new_comp.append(complexity_split(e, pm))\n",
    "    new_acc.append(accuracy(e, pm, pu_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.171377245641041\n",
      "3.686277088613336\n"
     ]
    }
   ],
   "source": [
    "print(complexity(o, pm))\n",
    "print(accuracy(o, pm, pu_w))\n",
    "\n",
    "qm_w = m_hat(qw_m[1100], pm, pu_m)\n",
    "a = DKL(pu_m[0], qm_w, axis=1)\n",
    "b = DKL(pu_m[1], qm_w, axis=1)\n",
    "c = DKL(pu_m[2], qm_w, axis=1)\n",
    "a.shape\n",
    "stacked = np.stack((a, b, c))\n",
    "sa = softmax(stacked, beta=beta_schedule[1100], axis=1)\n",
    "pwsa = (w[0, :78]*sa)\n",
    "(pwsa/pwsa.sum(axis=1).reshape(-1, 1)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.33327011,  4.47358122,  5.16873024, 12.03267535, 11.8366125 ,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325,\n",
       "       49.64319325, 49.64319325, 49.64319325, 49.64319325, 49.64319325])"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div = DKL(pu_m[0, :], new_pu_w, axis=1)\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7919738835890051"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(q, pm, pu_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1290203489744936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12902034897435277"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(complexity(o, pm))\n",
    "accuracy(o, pm, pu_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(dxy, beta=1, axis=None):\n",
    "    \"\"\":return\n",
    "        axis = None: pXY propto exp(-beta * dxy)\n",
    "        axis = 1: pY_X propto exp(-beta * dxy)\n",
    "        axis = 0: pX_Y propto exp(-beta * dxy)\n",
    "    \"\"\"\n",
    "    log_z = logsumexp(-beta * dxy, axis, keepdims=True)\n",
    "    return np.exp(-beta * dxy - log_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = beta_schedule[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9758117563384303e-05"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ib_curve[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.91046177e-01, 2.56896118e-01, 1.51183447e-01, 8.55146590e-04,\n",
       "        1.91114948e-05],\n",
       "       [3.51090163e-01, 5.74622798e-01, 7.34634014e-02, 5.97786034e-04,\n",
       "        2.25851520e-04],\n",
       "       [1.98504618e-01, 2.35554843e-02, 4.94941198e-01, 2.82977641e-01,\n",
       "        2.10583353e-05],\n",
       "       ...,\n",
       "       [8.34086257e-01, 7.54530351e-02, 7.39749515e-02, 1.64827999e-02,\n",
       "        2.95672276e-06],\n",
       "       [6.79966577e-01, 3.98140962e-02, 2.09699324e-01, 7.05140303e-02,\n",
       "        5.97295562e-06],\n",
       "       [2.59388445e-01, 6.71360429e-01, 6.87213462e-02, 1.92262813e-04,\n",
       "        3.37516538e-04]])"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw_m[139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.concatenate((qw_m[138], np.zeros((330, 325))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8030636608362567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7919738835890051"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(complexity(q, pm))\n",
    "accuracy(q, pm, pu_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8030636683498145\n",
      "0.792957196977893\n"
     ]
    }
   ],
   "source": [
    "print(ib_curve[0][138])\n",
    "print(ib_curve[1][138])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ib_curve[0], ib_curve[1])\n",
    "np.argmax(ib_curve[0]>=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.76124723e-01, 6.35998075e-03, 2.48341036e-07, ...,\n",
       "        2.21206309e-09, 4.73529757e-02, 2.40406320e-07],\n",
       "       [3.49275657e-02, 1.37134662e-03, 4.03576579e-07, ...,\n",
       "        1.56079620e-07, 3.85553573e-02, 6.05901524e-05],\n",
       "       [6.03476117e-06, 1.97902116e-01, 7.36698875e-01, ...,\n",
       "        6.24576070e-02, 8.89667785e-07, 4.12011883e-06],\n",
       "       ...,\n",
       "       [1.99431692e-02, 2.60929093e-04, 4.29230185e-05, ...,\n",
       "        1.05637759e-03, 3.57789531e-01, 1.36024557e-08],\n",
       "       [1.40123552e-04, 4.08256098e-02, 1.37111509e-02, ...,\n",
       "        2.13269110e-02, 9.63760788e-04, 2.32520510e-06],\n",
       "       [4.20176873e-03, 1.53999141e-03, 6.91159557e-07, ...,\n",
       "        1.67863334e-08, 2.45676972e-03, 9.83491734e-05]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw_m[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7612438757596145"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div = DKL(o[2][0, :], o[3][0, :])\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17719/290527554.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/venv37/lib/python3.7/site-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0ma_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/venv37/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/venv37/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "x = np.exp(-beta*div)*o[1]\n",
    "x/x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.19200000e+03, 8.02309323e+03, 7.85766906e+03, ...,\n",
       "       1.00012516e+00, 1.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-35801.45911960366\n",
      "100\n",
      "35901.45911960366\n",
      "8192.0\n",
      "[0.01540954 0.00141249 0.01657937 0.00410181 0.00027444]\n",
      "(330, 330)\n",
      "-35801.45911960366\n",
      "2.134709081502706e-06\n",
      "-35801.45912173837\n",
      "[0.01540954 0.00141249 0.01657937 0.00410181 0.00027444]\n",
      "(330, 330)\n"
     ]
    }
   ],
   "source": [
    "o = deterministic_annealing(pm, pu_m, np.diag(np.ones(330)), beta_schedule[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.50945402318856\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17719/937417190.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex_mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#- accuracy(obj.encoder, np.diag(np.ones(4))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17719/3760140875.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(pMW, pU_M)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \"\"\"\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# pMW = pW_M * pM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mpWU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpMW\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mpU_M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mMI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpWU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 3)"
     ]
    }
   ],
   "source": [
    "obj = ex_mid\n",
    "print(complexity(obj.encoder))\n",
    "print(accuracy(obj.encoder, np.diag(np.ones(4))))\n",
    "print(MI(np.diag(np.ones(4)) * obj.p_m)) #- accuracy(obj.encoder, np.diag(np.ones(4))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = mid_complexity_encoder\n",
    "obj = obj/obj.sum()\n",
    "pw, pjm = margins(obj)\n",
    "encoder = obj/pjm\n",
    "zas_mod = IBNamingModel(pjm, np.diag(np.ones(4)), beta_schedule, beta_schedule, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/ais/hal9000/datasets/reddit/stance_pipeline/classifiers/temp.zip',\n",
       " <http.client.HTTPMessage at 0x7fca5077fd50>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from urllib.request import urlretrieve\n",
    "# DEFAULT_MODEL_URL = 'https://www.dropbox.com/s/70w953orv27kz1o/IB_color_naming_model.zip?dl=1'\n",
    "# urlretrieve(DEFAULT_MODEL_URL, \"/ais/hal9000/datasets/reddit/stance_pipeline/classifiers/\" + 'temp.zip')\n",
    "# from zipfile import ZipFile\n",
    "# with ZipFile(model_dir + 'temp.zip', 'r') as zf:\n",
    "#     zf.extractall(model_dir)\n",
    "#     os.remove(model_dir + 'temp.zip')\n",
    "#     os.rename(model_dir + 'IB_color_naming_model/IB_color_naming.pkl', model_dir + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = mid_complexity_encoder\n",
    "obj = (obj/obj.sum()).T # transform to meanings on rows\n",
    "pw, pjm = margins(obj)\n",
    "encoder = (obj/pjm).T\n",
    "m_hat(encoder, pjm, np.diag(np.ones(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "xs = []\n",
    "ys = []\n",
    "for ib in all_ibs:\n",
    "    names.append(ib.com_name)\n",
    "    xs.append(ib.complexity)\n",
    "    ys.append(ib.informativeness)\n",
    "plt.scatter(xs, ys)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3da9994af9e3093f34be5556416449be7c3908df46ffc29ccdba7bd3fd3a7b92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
